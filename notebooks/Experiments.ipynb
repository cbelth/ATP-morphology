{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# packages\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# custom code\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from utils import load_word_to_ipa, load_pairs\n",
    "from atp import ATP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Development\n",
    "\n",
    "The following cells generate Figure 1 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_children = 100\n",
    "\n",
    "ing = [0] * 20\n",
    "s = [0] * 20\n",
    "d = [0] * 20\n",
    "\n",
    "word_to_ipa = load_word_to_ipa()\n",
    "\n",
    "for child in range(num_children):\n",
    "    if child % 10 == 0:\n",
    "        print(f'==== Child {child} ====')\n",
    "    vocabs = list(glob.glob(f'../data/english/growth/child-{child}/*.txt'))\n",
    "    vocabs = sorted(vocabs, key=lambda it: int(it.split('/')[-1].split('.txt')[0]))\n",
    "    for i, vocab in enumerate(vocabs):\n",
    "        pairs = list()\n",
    "        feature_space = set()\n",
    "        for line in open(vocab, 'r'):\n",
    "            lemma, inflected, feats = line.strip().split()\n",
    "            lemma_ipa = word_to_ipa[lemma]\n",
    "            inflected_ipa = word_to_ipa[inflected]\n",
    "            feature_space.update(feats.split(';'))\n",
    "            pairs.append((lemma_ipa, inflected_ipa, tuple(feats.split(';'))))\n",
    "        atp = ATP(feature_space=feature_space, apply_phonology=True)\n",
    "        atp.train(pairs)\n",
    "        \n",
    "        suffixes = set()\n",
    "        for leaf in atp.get_leaves():\n",
    "            if leaf.switch_statement.productive:\n",
    "                suffix = leaf.switch_statement.default_case.name.split('lemma')[-1].replace(' + ', '')\n",
    "                suffixes.add(suffix)\n",
    "        if 'z' in suffixes and 's' in suffixes:\n",
    "            suffixes.discard('z')\n",
    "        if 't' in suffixes and 'd' in suffixes:\n",
    "            suffixes.discard('t')\n",
    "        for suffix in suffixes:\n",
    "            if suffix == 'ɪŋ':\n",
    "                ing[i] += 1\n",
    "            if suffix in {'d', 't'}:\n",
    "                d[i] += 1\n",
    "            if suffix in {'s', 'z'}:\n",
    "                s[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grays = sns.color_palette('Greys')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "fontsize=40\n",
    "x = np.arange(50, 1050, 50)\n",
    "Z = num_children\n",
    "\n",
    "plt.plot(x, np.asarray(ing) / Z, '-o',  markersize=24, linewidth=12, color=grays[-4], label='-ing')\n",
    "plt.plot(x, np.asarray(s) / Z, '-o',  markersize=24, linewidth=12, color=grays[-2], linestyle=':', label='-s')\n",
    "plt.plot(x, np.asarray(d) / Z, '-o',  markersize=24, linewidth=12, color='black', label='-ed')\n",
    "\n",
    "plt.legend(fontsize=fontsize + 6)\n",
    "plt.xticks(np.arange(50, 1050, 150), fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.ylabel('Fraction Children with Rule', fontsize=fontsize)\n",
    "plt.xlabel('Child\\'s Vocabulary Size', fontsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Development\n",
    "\n",
    "The following cells generate Figure 1 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seeds = 100\n",
    "train_sizes = [50, 100, 200, 300, 400]\n",
    "\n",
    "en = [0] * len(train_sizes)\n",
    "n = [0] * len(train_sizes)\n",
    "e = [0] * len(train_sizes)\n",
    "null = [0] * len(train_sizes)\n",
    "er = [0] * len(train_sizes)\n",
    "s = [0] * len(train_sizes)\n",
    "\n",
    "for i, size in enumerate(train_sizes):\n",
    "    for seed in range(num_seeds):\n",
    "        fname = f'../data/german/growth/train{size}_{seed}.txt'\n",
    "        pairs, feature_space = load_pairs(fname, 'german')\n",
    "        atp = ATP(feature_space=feature_space)\n",
    "        atp.train(pairs)\n",
    "\n",
    "        suffixes = set()\n",
    "        for leaf in atp.get_leaves():\n",
    "            if leaf.switch_statement.productive:\n",
    "                suffix = leaf.switch_statement.default_case.name.split('lemma')[-1].replace(' + ', '')\n",
    "                suffixes.add(suffix)\n",
    "        for suffix in suffixes:\n",
    "            if suffix == 'en':\n",
    "                en[i] += 1\n",
    "            if suffix == 'e':\n",
    "                e[i] += 1\n",
    "            if suffix == 'n':\n",
    "                n[i] += 1\n",
    "            if suffix == '':\n",
    "                null[i] += 1\n",
    "            if suffix == 'er':\n",
    "                er[i] += 1\n",
    "            if suffix == 's':\n",
    "                s[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "fontsize=40\n",
    "x = train_sizes\n",
    "Z = num_seeds\n",
    "lw = 14\n",
    "ms = 26\n",
    "\n",
    "ca = grays\n",
    "\n",
    "plt.plot(x, np.asarray(n) / Z, '-o', markersize=ms, linewidth=lw,    color=ca[1],  linestyle='-',  label='-n')\n",
    "plt.plot(x, np.asarray(null) / Z, '-o', markersize=ms, linewidth=lw, color=ca[1],  linestyle=':',  label='-∅')\n",
    "plt.plot(x, np.asarray(e) / Z, '-o',  markersize=ms, linewidth=lw,   color=ca[2],  linestyle='-',  label='-e')\n",
    "plt.plot(x, np.asarray(en) / Z, '-o', markersize=ms, linewidth=lw,   color=ca[3],  linestyle=':',  label='-en')\n",
    "plt.plot(x, np.asarray(er) / Z, '-o',  markersize=ms, linewidth=lw,  color=ca[4],  linestyle='-',  label='-er')\n",
    "plt.plot(x, np.asarray(s) / Z, '-o',  markersize=ms, linewidth=lw,   color=ca[5],  linestyle=':',  label='-s')\n",
    "\n",
    "plt.legend(fontsize=fontsize - 1, loc=(0.75, 0.21), facecolor='white', framealpha=1.0)\n",
    "\n",
    "plt.xticks([100, 200, 300, 400], fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.ylabel('Fraction Children with Rule', fontsize=fontsize)\n",
    "plt.xlabel('Child\\'s Vocabulary Size', fontsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Wug test\n",
    "\n",
    "The following cells generate Table 1. While ATP is deterministic, the numbers may differ some due to arbitrariness at runtime, such as hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/german/german_wug.csv')\n",
    "df = df[df['Q_Task'] == 'production'].fillna('')\n",
    "\n",
    "wugs = set()\n",
    "wug_to_child_preds = defaultdict(list)\n",
    "wug_to_rhyme = dict()\n",
    "suffixes = set()\n",
    "for wug, child_pred, suffix, rhyme in zip(df['Q_Lemma'], df['Q_PL_Form'], df['Q_PL_Label'], df['Q_Lemma_HasRhymes']):\n",
    "    wug, child_pred = wug.capitalize(), child_pred.capitalize()\n",
    "    wug = wug.replace(u'ä', 'a').replace(u'ü', 'u').replace(u'ö', 'o').replace(u'Ä', 'A').replace(u'Ü', 'U').replace(u'Ö', 'O')\n",
    "    child_pred = child_pred.replace(u'ä', 'a').replace(u'ü', 'u').replace(u'ö', 'o').replace(u'Ä', 'A').replace(u'Ü', 'U').replace(u'Ö', 'O')\n",
    "    \n",
    "    wugs.add(wug)\n",
    "    suffix = suffix.replace('umlaut_', '')\n",
    "    if suffix == 'umlaut':\n",
    "        suffix = 'zero'\n",
    "        assert(child_pred == wug)\n",
    "    wug_to_child_preds[wug].append(suffix)\n",
    "    suffixes.add(suffix)\n",
    "    \n",
    "    if suffix == 'en':\n",
    "        assert(child_pred[len(wug):] == 'en')\n",
    "        \n",
    "    if child_pred == f'{wug}n':\n",
    "        print(child_pred, wug)\n",
    "        \n",
    "    wug_to_rhyme[wug] = rhyme\n",
    "    \n",
    "wugs = sorted(wugs)\n",
    "    \n",
    "wug_to_TP_preds_CHILDES_N = defaultdict(list)\n",
    "wug_to_TP_preds_CHILDES_ques = defaultdict(list)\n",
    "\n",
    "def update(result_dict, model_pred, wug):\n",
    "    suffix = model_pred[len(wug):]\n",
    "    if suffix == '':\n",
    "        result_dict[wug].append('zero')\n",
    "    elif suffix == 'n':\n",
    "        result_dict[wug].append('en')\n",
    "    elif suffix in suffixes:\n",
    "        result_dict[wug].append(suffix)\n",
    "    else:\n",
    "        result_dict[wug].append('other')\n",
    "\n",
    "for i in range(500):\n",
    "    _pairs, feature_space = load_pairs(f'../data/german/growth/train400_{i}.txt', lang='german')\n",
    "    atp = ATP(feature_space=feature_space)\n",
    "    atp.train(_pairs)\n",
    "    for wug in wugs:\n",
    "        update(wug_to_TP_preds_CHILDES_N, atp.inflect(wug, ('N',)), wug)\n",
    "        update(wug_to_TP_preds_CHILDES_ques, atp.inflect_no_feat(wug, ()), wug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(preds):\n",
    "    dist = defaultdict(int)\n",
    "    for p in preds:\n",
    "        dist[p] += 1\n",
    "    return dict(dist)\n",
    "\n",
    "models = {'CHILDES_N': wug_to_TP_preds_CHILDES_N, \n",
    "          'CHILDES_?': wug_to_TP_preds_CHILDES_ques}\n",
    "\n",
    "model_res = dict()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    suffix_to_percentage_R = defaultdict(int)\n",
    "    suffix_to_percentage_NR = defaultdict(int)\n",
    "    pearsons = dict()\n",
    "    Z_R = 0\n",
    "    Z_NR = 0\n",
    "\n",
    "    for s in suffixes:\n",
    "        child_p = list()\n",
    "        model_p = list()\n",
    "        for wug in wugs:\n",
    "            child_dist = get_dist(wug_to_child_preds[wug])\n",
    "            model_dist = get_dist(model[wug]) # Neuter with analogy\n",
    "            child_p.append((child_dist[s] / sum(child_dist.values()) if s in child_dist else 0))\n",
    "            model_p.append((model_dist[s] / sum(model_dist.values()) if s in model_dist else 0))\n",
    "\n",
    "            if s in model_dist:\n",
    "                if wug_to_rhyme[wug]:\n",
    "                    suffix_to_percentage_R[s] += model_dist[s]\n",
    "                    Z_R += model_dist[s]\n",
    "                else:\n",
    "                    suffix_to_percentage_NR[s] += model_dist[s]\n",
    "                    Z_NR += model_dist[s]\n",
    "                    \n",
    "        rho = spearmanr(child_p, model_p)\n",
    "        if rho.pvalue < 0.05:\n",
    "            pearsons[s] = f'{round(rho.correlation, 2)}*'\n",
    "        else:\n",
    "            pearsons[s] = rho.correlation\n",
    "            \n",
    "    for s in suffix_to_percentage_R:\n",
    "        suffix_to_percentage_R[s] /= Z_R\n",
    "\n",
    "    for s in suffix_to_percentage_NR:\n",
    "        suffix_to_percentage_NR[s] /= Z_NR\n",
    "        \n",
    "    model_res[model_name] = {'R': dict(suffix_to_percentage_R), \n",
    "                             'NR': dict(suffix_to_percentage_NR), \n",
    "                             'rho': dict(pearsons)}\n",
    "\n",
    "metrics = ['R', 'NR', 'rho']\n",
    "\n",
    "def get_res_for_suffix(suf):\n",
    "    return list(model_res['CHILDES_N'][metric][suf] if suf in model_res['CHILDES_N'][metric] else '' for metric in metrics) + list(model_res['CHILDES_?'][metric][suf] if suf in model_res['CHILDES_?'][metric] else '' for metric in metrics)\n",
    "\n",
    "def pretty(vals):\n",
    "    return list(round(v, 2) if type(v) is not str else v for v in vals)\n",
    "\n",
    "en_row = pretty(get_res_for_suffix('en'))\n",
    "e_row = pretty(get_res_for_suffix('e'))\n",
    "zero_row = pretty(get_res_for_suffix('zero'))\n",
    "er_row = pretty(get_res_for_suffix('er'))\n",
    "s_row = pretty(get_res_for_suffix('s'))\n",
    "other_row = pretty(get_res_for_suffix('other'))\n",
    "\n",
    "pd.DataFrame.from_dict({'': ['%R', '%NR', 'rho', '%R', '%NR', 'rho'],\n",
    "                        '-(e)n': en_row, \n",
    "                        '-e': e_row,\n",
    "                        '-zero': zero_row,\n",
    "                        '-er': er_row,\n",
    "                        '-s': s_row,\n",
    "                        'other': other_row},\n",
    "                       columns=['', '', 'A', '', 'D', ''],\n",
    "                       orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
